\section{Introduction}
\label{sec:intro}

Software libraries provide an excellent mechanism for practical
software reuse. Each library provides its functionality through the
Application Programming Interfaces (APIs). The library's designers
have the intent for developers to use the APIs in specific
combinations and orders to achieve its functionality. Such correct API
usages are often described in {\em API specifications}. A common
phenomenon in programming with libraries is API misuses. API misuses
are the incorrect usages that violate the usage constraints of the
APIs involving in an API usage to achieve certain task.  For example,
to correctly use an \code{Iterator}, one must check that
\code{Iterator.hasNext()} returns \code{true} before calling
\code{Iterator.next()} on the \code{Iterator} object. Otherwise,
an \code{NoSuchElementException} will be thrown at run-time.

API misuses have been shown to cause several issues ranging from
run-time errors, program crashes, null-pointer exceptions, to security
vulnerabilities~\cite{mudetect-msr19,MM13,SHA15,FHMB+12,EBFK13,NKMB16,GIJA+12,ANNN+16}. To
mitigate API misuse, researchers have proposed several
\emph{API-misuse
detectors}~\cite{LZ05,L07,WZL07,RGJ07,NNP+09,AX09,TX09,TX09b,WZ11,MM13,NPVN16}.
These detectors analyze a given \emph{API usage}, i.e., a code snippet
that use a given API, and detect if it contains an API misuse.  In
general, the API misuse detection approaches can be broadly classified
into two categories. In the first category, the approaches mine the
API specifications from the API documentation and then check the code
against
them~\cite{ase22,jdoctor-issta18,zhou-icse17,c2s-fse20}. However,
these approaches are limited in two ways. First, the lack of
specifications in the API documentation in general has been hindering
the libraries' users in understanding and using the APIs in the
correct manner. The reason is that manually defining specifications is
time-consuming. The libraries' developers must spend additional time
and effort for documenting API specifications. Second, the existing
API specification mining approaches work only for specific types of
specifications, e.g., behavioral exceptions~\cite{ase22}, temporal
orders~\cite{icse17-nier}, etc. Moreover, they are limited due to
explicitly pre-defined rules for lexical and semantic matching of
texts to derive conditions from API
documentation~\cite{zhou-icse17,jdoctor-issta18}.

%Incorrect usages of an Application Programming Interface (API), or \emph{API misuses}, are violations of (implicit) \emph{usage constraints} of the API.
%An example of a usage constraint is having to check that \code{hasNext()} returns \code{true} before calling \code{next()} on an \code{Iterator}, in order to avoid a \code{NoSuchElementException} at runtime.
%API misuse is a prevalent cause of software bugs, crashes, and vulnerabilities~\cite{MM13,SHA15,FHMB+12,EBFK13,NKMB16,GIJA+12,ANNN+16}.

% While good API documentation might mitigate the problem, a recent study shows that Android developers, for example, prefer informal references, such as StackOverflow, over official API documentation, even though the former promote many insecure API usages~\cite{ABFKMS16}.
% Previous work also indicates that developers struggle with well-documented APIs, such as Java's \code{Iterator}~\cite{ANNN+17}.
% Therefore, in addition to improving documentation, techniques have been developed to detect misuses and warn developers about them.
%

The second category of API misuse detectors relies on {\em pattern
  mining}~\cite{LZ05,L07,WZL07,RGJ07,NNP+09,AX09,TX09,TX09b,WZ11,MM13,NPVN16}. First,
they mine from the large code corpus the {\em API usage patterns},
which are the API usages occurring frequently. These mined API usage
patterns are considered as the correct ones. The given code is then
processed to check for any deviations from these patterns.  If true,
it is considered as a potential API misuse. Unfortunately, the
reported precision of such detectors is typically low and a recent
study~\cite{ANNN+17} showed that their recall is also very low.
%Tien: key issue
The still-prevalent problems of API misuse detectors have been
reported~\cite{LHXRM16,ABFKMS16}. First, the mining-based detectors
cannot differentiate infrequent from invalid usage. This is an
inherent issue with mining because these approaches need to set a
pre-defined threshold for frequent API usage patterns. This also leads
to the second problem: the detectors often learn a pattern and then
report instances of alternative usages as violations. Alternative
usage is a different functionally correct way to use an API to achieve
the same functionality.


%%%
%%%Previous work identified individual as well as common strengths and weaknesses of existing detectors~\cite{ANNN+17} in an empirical study using the open-source benchmark MUBench~\cite{mubench}.
%%%In this paper, we investigate whether addressing the reported weaknesses indeed leads to better performance in practice.
%%%% representation
%%%Therefore, we design a new misuse detector, MUDetect.
%%%MUDetect encodes API usages as API-Usage Graphs, a comprehensive usage representation that captures different types of API misuses.
%%%% domain knowledge
%%%MUDetect employs a greedy, frequent-subgraph-mining algorithm to mine patterns and a specialized graph-matching strategy to identify pattern violations. % (violating) pattern occurrences.
%%%Both components consider code semantics to improve the overall detection capabilities.
%%%% ranking
%%%On top, MUDetect uses an empirically optimized ranking strategy to effectively rank true positives.
%%%While previous detectors mostly target a per-project setting~\cite{ANNN+17}, MUDetect also works in a cross-project setting, where it mines thousands of usage examples from third-party projects.
%%%
%%%% evaluation
%%%We assess the precision and recall of MUDetect and show that it outperforms the \checkNum{four} state-of-the-art detectors evaluated in prior work~\cite{ANNN+17}.
%%%% dataset
%%%In our evaluation, we extended MUBench by \checkNum{107} real-world misuses identified in a recent study on run-time verification~\cite{LHXRM16}---\checkNum{more than doubling} its size---to ensure that our design decisions generalize.
%%%%
%%%%results
%%%% intra project
%%%We show that, in a setting with perfect training data, MUDetect achieves a recall of \checkNum{72.5\%}, which is \checkNum{20.3\%} higher than the next best detector and over \checkNum{50\%} higher than the other detectors.
%%%In the typical per-project setting, MUDetect achieves recall of \checkNum{20.9\%}, which is \checkNum{10.2\%} better than the second-best detector, and precision of \checkNum{21.9\%}, which is \checkNum{13.1\%} better than the second-best detector.
%%%% cross project
%%%In a cross-project setting, MUDetect's recall and precision again improve significantly to \checkNum{42.2\%} and \checkNum{33.0\%}, respectively.
%%%%
%%%% pull requests
%%%Throughout the experiments, MUDetect identified 27 previously unknown misuses, which we reported in \checkNum{eight} pull requests (PRs).
%%%To date, \checkNum{three} of the PRs got accepted, demonstrating that MUDetect identifies actual issues in current software projects.


%%%To summarize, this paper makes the following contributions:
%%%%
%%%\begin{itemize}[leftmargin=*]
%%%  \item AUG, a graph-based representation of API usages that captures all usage properties relevant for identifying misuses.
%%%  \item Code-semantic-aware, greedy frequent-subgraph-mining and graph-matching algorithms to identify patterns within and across projects and (violating) instances in a target codebase.
%%%  \item MUDetect, a (cross-project) misuse detector.
%%%  \item An empirical study of ranking strategies to improve precision.
%%%  \item An empirical evaluation that compares MUDetect to existing detectors, and includes an analysis of the results to identify further opportunities for improvement.
%%%  \item Fixes for all previously unknown misuses identified by MUDetect, for external validation of the findings' relevance.
%%%\end{itemize}
%%%
%%%We publish our MUBench extension, MUDetect's implementation, and all experiment data, tooling, and results~\cite{artifact-page}.

In this paper, we address those above problems with the mining-based
API misuse detection approaches. We introduce {\tool}, a
learning-based API misuse detection approach, that leverages two key
insights to overcome those issues. First, we use a graph
representation, called Augmented Usage Graph
(AUG)~\cite{mudetect-msr19}, to represent the program dependencies and
relations among the API elements as well as other program elements in
an API usage. We then use the Graph Convolutional Network (GCN) to
model the API usage by encoding the corresponding AUG. Second, due to
the lack of training data for the code with API misuses, we apply
several techniques for data augmentation.


%We extract the AUGs from the complete, compilable source code using
%the APIs from a large code corpus. We then enhance the AUGs with all
%the FQNs because the training code is compilable.
